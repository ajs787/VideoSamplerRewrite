import time
import pandas as pd
import logging
from SamplerFunctions import sample_video
from WriteToDataset import write_to_dataset
import argparse
import subprocess
import multiprocessing
from multiprocessing import freeze_support
import concurrent
import re
import os

format = "%(asctime)s: %(message)s"
logging.basicConfig(format=format, level=logging.INFO, datefmt="%H:%M:%S")


def main():
    file_list = []
    try:
        prep_file = open("dataprep.log", "r+")
        prep_file.truncate(0)
        prep_file.close()
    except:
        logging.info("prep file not found")
    try:
        start = time.time()
        parser = argparse.ArgumentParser(
            description="Prepare datasets for Deep Neural Network (DNN) training using video data."
        )
        parser.add_argument(
            "--dataset_path",
            type=str,
            help="Path to the dataset, defaults to .",
            default=".",
        )
        parser.add_argument(
            "--dataset-search-string",
            type=str,
            help="Grep string to get the datasets, defaults to dataset_*.csv",
            default="dataset_*.csv",
        )
        parser.add_argument(
            "--number-of-samples",
            type=int,
            help="the number of samples max that will be gathered by the sampler, defalt=1000",
            default=1000,
        )
        parser.add_argument(
            "--max-workers",
            type=int,
            help="The number of workers to use for the multiprocessing, default=15",
            default=15,
        )
        parser.add_argument(
            "--frames-per-sample",
            type=int,
            help="The number of frames per sample, default=1",
            default=1,
        )
        parser.add_argument(
            "--normalize",
            type=bool,
            help="Normalize the images, default=True",
            default=True,
        )
        parser.add_argument(
            "--out-channels",
            type=int,
            help="The number of output channels, default=1",
            default=1,
        )
        parser.add_argument(
            "--bg-subtract",
            type=str,
            choices=["mog2", "knn"],
            help="The background subtraction method to use, defaults to None [EXPERIMENTIAL, not implemented yet]",
            default=None,
        )

        args = parser.parse_args()
        number_of_samples = args.number_of_samples
        command = f"ls {os.path.join(args.dataset_path, args.dataset_search_string)}"
        ansi_escape = re.compile(r"\x1B\[[0-?]*[ -/]*[@-~]")
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        file_list = sorted(
            [ ansi_escape.sub("", line).strip() for line in result.stdout.splitlines()]
        )

        logging.info(f"File List: {file_list}")

        total_dataframe = pd.DataFrame()
        for file in file_list:
            df = pd.read_csv(file)
            df["data_file"] = file
            total_dataframe = pd.concat([total_dataframe, df])
            subprocess.run(
                f"rm -rf {file.replace('.csv', '')}_samplestemporary", shell=True
            )
            subprocess.run(
                f"mkdir {file.replace('.csv', '')}_samplestemporary", shell=True
            )
            subprocess.run(
                f"rm -rf {file.replace('.csv', '')}_samplestemporarytxt", shell=True
            )
            subprocess.run(
                f"mkdir {file.replace('.csv', '')}_samplestemporarytxt", shell=True
            )

        data_frame_list = [group for _, group in total_dataframe.groupby("file")]
        logging.info(len(data_frame_list))
        for dataset in data_frame_list:
            dataset.reset_index(drop=True, inplace=True)
        for i in range(3):
            logging.info(data_frame_list[i].head())
        with concurrent.futures.ProcessPoolExecutor(
            max_workers=min(args.max_workers, multiprocessing.cpu_count())
        ) as executor:
            futures = [
                executor.submit(
                    sample_video,
                    dataset.loc[0, "file"],
                    dataset,
                    number_of_samples,
                    args.frames_per_sample,
                    args.normalize,
                    args.out_channels,
                    args.bg_subtract,
                    args.frames_per_sample,
                )
                for dataset in data_frame_list
            ]
            concurrent.futures.wait(futures)
            logging.info(f"Submitted {len(futures)} tasks to the executor")
            logging.info(f"Executor mapped")
            
        result = subprocess.run("ls *temporary", shell=True, capture_output=True, text=True)
        text = ansi_escape.sub(result.stdout).split()
        logging.info(f"Samples sampled: {text}")
        with concurrent.futures.ThreadPoolExecutor(
            max_workers=min(args.max_workers, multiprocessing.cpu_count())
        ) as executor:
            futures = [
                executor.submit(
                    write_to_dataset,
                    file.replace(".csv", "") + "_samplestemporary",
                    file.replace(".csv", ".tar"),
                    args.frames_per_sample,
                    args.out_channels,
                )
                for file in file_list
            ]
            concurrent.futures.wait(futures)
            logging.info(f"Submitted {len(futures)} tasks to the executor")
            logging.info(f"Executor mapped")

        end = time.time()
        logging.info(f"Time taken to run the the script: {end - start} seconds")

    except Exception as e:
        logging.error(f"An error occurred in main function: {e}")
        raise e
    

    finally:
        
        for file in file_list:
            subprocess.run(
                f"rm -rf {file.replace('.csv', '')}_samplestemporary", shell=True
            )
            subprocess.run(
                f"rm -rf {file.replace('.csv', '')}_samplestemporarytxt", shell=True
            )


if __name__ == "__main__":
    freeze_support()
    main()
